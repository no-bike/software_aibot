#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹è·¯å¾„é…ç½®

ç»Ÿä¸€ç®¡ç†å„ç§AIæ¨¡å‹å’Œå·¥å…·çš„ç¼“å­˜è·¯å¾„è®¾ç½®
"""

import os
import logging

logger = logging.getLogger(__name__)

class ModelPathConfig:
    """æ¨¡å‹è·¯å¾„é…ç½®ç±»"""
    
    def __init__(self, base_cache_dir: str = "E:/AI_Models_Cache"):
        """
        åˆå§‹åŒ–æ¨¡å‹è·¯å¾„é…ç½®
        
        Args:
            base_cache_dir: åŸºç¡€ç¼“å­˜ç›®å½•ï¼Œé»˜è®¤ä¸ºEç›˜
        """
        self.base_cache_dir = base_cache_dir
        
        # å„ç§æ¨¡å‹çš„å­ç›®å½•
        self.transformer_cache_dir = os.path.join(base_cache_dir, "transformers")
        self.jieba_cache_dir = os.path.join(base_cache_dir, "jieba")
        self.llm_blender_cache_dir = os.path.join(base_cache_dir, "llm_blender")
        self.huggingface_cache_dir = os.path.join(base_cache_dir, "huggingface")
        
        # ç¡®ä¿æ‰€æœ‰ç›®å½•å­˜åœ¨
        self._ensure_directories()
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        self._setup_environment_variables()
        
        logger.info(f"ğŸ¯ æ¨¡å‹ç¼“å­˜åŸºç¡€ç›®å½•: {self.base_cache_dir}")
    
    def _ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [
            self.base_cache_dir,
            self.transformer_cache_dir,
            self.jieba_cache_dir,
            self.llm_blender_cache_dir,
            self.huggingface_cache_dir
        ]
        
        for directory in directories:
            try:
                os.makedirs(directory, exist_ok=True)
                logger.debug(f"ğŸ“ ç¡®ä¿ç›®å½•å­˜åœ¨: {directory}")
            except Exception as e:
                logger.error(f"âŒ æ— æ³•åˆ›å»ºç›®å½• {directory}: {e}")
    
    def _setup_environment_variables(self):
        """è®¾ç½®ç¯å¢ƒå˜é‡"""
        env_vars = {
            "TRANSFORMERS_CACHE": self.transformer_cache_dir,
            "HF_HOME": self.huggingface_cache_dir,
            "HF_CACHE_HOME": self.huggingface_cache_dir,
            "TORCH_HOME": os.path.join(self.base_cache_dir, "torch"),
        }
        
        for var_name, var_value in env_vars.items():
            os.environ[var_name] = var_value
            logger.debug(f"ğŸ”§ è®¾ç½®ç¯å¢ƒå˜é‡: {var_name}={var_value}")
    
    def get_jieba_cache_file(self) -> str:
        """è·å–jiebaç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.jieba_cache_dir, "jieba.cache")
    
    def get_model_cache_dir(self, model_type: str) -> str:
        """
        è·å–ç‰¹å®šæ¨¡å‹ç±»å‹çš„ç¼“å­˜ç›®å½•
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ('transformer', 'jieba', 'llm_blender', ç­‰)
        
        Returns:
            å¯¹åº”çš„ç¼“å­˜ç›®å½•è·¯å¾„
        """
        cache_dirs = {
            'transformer': self.transformer_cache_dir,
            'jieba': self.jieba_cache_dir,
            'llm_blender': self.llm_blender_cache_dir,
            'huggingface': self.huggingface_cache_dir
        }
        
        return cache_dirs.get(model_type, self.base_cache_dir)
    
    def clear_cache(self, model_type: str = None):
        """
        æ¸…ç†æŒ‡å®šç±»å‹çš„ç¼“å­˜ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
        
        Args:
            model_type: è¦æ¸…ç†çš„æ¨¡å‹ç±»å‹ï¼ŒNoneè¡¨ç¤ºæ¸…ç†æ‰€æœ‰
        """
        import shutil
        
        if model_type:
            cache_dir = self.get_model_cache_dir(model_type)
            if os.path.exists(cache_dir):
                try:
                    shutil.rmtree(cache_dir)
                    os.makedirs(cache_dir, exist_ok=True)
                    logger.info(f"ğŸ§¹ å·²æ¸…ç† {model_type} ç¼“å­˜: {cache_dir}")
                except Exception as e:
                    logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        else:
            logger.warning("âš ï¸ è¯·æŒ‡å®šè¦æ¸…ç†çš„æ¨¡å‹ç±»å‹ï¼Œé¿å…æ„å¤–æ¸…ç†æ‰€æœ‰ç¼“å­˜")
    
    def get_cache_info(self) -> dict:
        """è·å–ç¼“å­˜ç›®å½•ä¿¡æ¯"""
        def get_dir_size(path):
            """è®¡ç®—ç›®å½•å¤§å°"""
            total_size = 0
            try:
                for dirpath, dirnames, filenames in os.walk(path):
                    for filename in filenames:
                        filepath = os.path.join(dirpath, filename)
                        if os.path.exists(filepath):
                            total_size += os.path.getsize(filepath)
            except Exception as e:
                logger.debug(f"è®¡ç®—ç›®å½•å¤§å°å¤±è´¥ {path}: {e}")
            return total_size
        
        cache_info = {
            'base_dir': self.base_cache_dir,
            'directories': {}
        }
        
        for name, path in {
            'transformer': self.transformer_cache_dir,
            'jieba': self.jieba_cache_dir,
            'llm_blender': self.llm_blender_cache_dir,
            'huggingface': self.huggingface_cache_dir
        }.items():
            cache_info['directories'][name] = {
                'path': path,
                'exists': os.path.exists(path),
                'size_bytes': get_dir_size(path) if os.path.exists(path) else 0
            }
        
        return cache_info

# å…¨å±€é…ç½®å®ä¾‹
_model_path_config = None

def get_model_path_config(base_cache_dir: str = "E:/AI_Models_Cache") -> ModelPathConfig:
    """è·å–å…¨å±€æ¨¡å‹è·¯å¾„é…ç½®å®ä¾‹"""
    global _model_path_config
    if _model_path_config is None:
        _model_path_config = ModelPathConfig(base_cache_dir)
        logger.info("âœ… æ¨¡å‹è·¯å¾„é…ç½®åˆå§‹åŒ–å®Œæˆ")
    return _model_path_config

def setup_jieba_cache():
    """è®¾ç½®jiebaç¼“å­˜è·¯å¾„"""
    import jieba
    config = get_model_path_config()
    jieba_cache_file = config.get_jieba_cache_file()
    jieba.dt.cache_file = jieba_cache_file
    logger.info(f"ğŸˆ³ Jiebaç¼“å­˜æ–‡ä»¶: {jieba_cache_file}")

# åœ¨æ¨¡å—å¯¼å…¥æ—¶è‡ªåŠ¨è®¾ç½®
if __name__ != "__main__":
    # è‡ªåŠ¨åˆå§‹åŒ–é…ç½®ï¼ˆé™¤éæ˜¯ç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼‰
    get_model_path_config() 