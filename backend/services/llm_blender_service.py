#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM-Blender èåˆæœåŠ¡

é›†æˆ LLM-Blender çš„é«˜çº§èåˆåŠŸèƒ½åˆ° software_aibot é¡¹ç›®ä¸­
æä¾›åŸºäºè´¨é‡æ’åºå’Œç”Ÿæˆèåˆçš„æ™ºèƒ½å›ç­”åˆå¹¶æœåŠ¡
"""

import os
import time
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path
import sys
import asyncio
import json
import aiohttp

# è¿‡æ»¤å¸¸è§çš„éå…³é”®è­¦å‘Š
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning, module="dataclasses_json")
warnings.filterwarnings("ignore", category=UserWarning, module="transformers.convert_slow_tokenizer")

# æ·»åŠ æœ¬åœ°llm_blenderè·¯å¾„
# LLM-Blenderç°åœ¨åœ¨servicesç›®å½•ä¸‹
current_dir = Path(__file__).parent  # servicesç›®å½•
llm_blender_path = current_dir / "LLM-Blender"
print(f"ğŸ” æŸ¥æ‰¾LLM-Blenderè·¯å¾„: {llm_blender_path}")
print(f"ğŸ” è·¯å¾„æ˜¯å¦å­˜åœ¨: {llm_blender_path.exists()}")
if llm_blender_path.exists():
    sys.path.insert(0, str(llm_blender_path))
    print(f"âœ… å·²æ·»åŠ è·¯å¾„åˆ°sys.path: {llm_blender_path}")
else:
    print(f"âŒ æœªæ‰¾åˆ°LLM-Blenderè·¯å¾„ï¼Œå½“å‰æ–‡ä»¶ä½ç½®: {Path(__file__)}")
    print(f"âŒ å½“å‰servicesç›®å½•: {current_dir}")
    print(f"âŒ å¯»æ‰¾çš„è·¯å¾„: {llm_blender_path}")
    
    # å°è¯•åˆ—å‡ºservicesç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
    try:
        contents = list(current_dir.iterdir())
        print(f"ğŸ“‚ servicesç›®å½•å†…å®¹: {[item.name for item in contents]}")
    except Exception as e:
        print(f"âŒ æ— æ³•åˆ—å‡ºservicesç›®å½•å†…å®¹: {e}")

# é…ç½®ç¯å¢ƒå˜é‡ï¼Œé¿å…CUDAå’Œç¬¦å·é“¾æ¥é—®é¢˜
os.environ["CUDA_VISIBLE_DEVICES"] = ""

import llm_blender
from llm_blender.blender.blender_utils import get_topk_candidates_from_ranks

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# DeepSeek API é…ç½®
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")  # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥

class LLMBlenderService:
    """LLM-Blender èåˆæœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ– LLM-Blender æœåŠ¡"""
        self.blender = None
        self.is_initialized = False
        self.ranker_loaded = False
        self.fuser_loaded = False
        
    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ– LLM-Blender"""
        if self.is_initialized:
            logger.debug("â™»ï¸ LLM-Blender æœåŠ¡å·²åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
            return
            
        try:
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ– LLM-Blender æœåŠ¡...")
            
            # åˆå§‹åŒ– Blender
            if self.blender is None:
                logger.info("ğŸ“¦ åˆ›å»º Blender å®ä¾‹...")
                self.blender = llm_blender.Blender()
            
            # åŠ è½½ Ranker (PairRM) - åªåŠ è½½ä¸€æ¬¡
            if not self.ranker_loaded:
                logger.info("ğŸ“¥ åŠ è½½ PairRM Ranker...")
                start_time = time.time()
                self.blender.loadranker(
                    "llm-blender/PairRM",
                    device="cpu"
                )
                ranker_time = time.time() - start_time
                self.ranker_loaded = True
                logger.info(f"âœ… Ranker åŠ è½½æˆåŠŸ ({ranker_time:.2f}s)")
            else:
                logger.debug("â™»ï¸ Ranker å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
            
            # å°è¯•åŠ è½½ Fuser (GenFuser) - åªåŠ è½½ä¸€æ¬¡
            if not self.fuser_loaded:
                try:
                    logger.info("ğŸ“¥ åŠ è½½ GenFuser...")
                    start_time = time.time()
                    self.blender.loadfuser(
                        "llm-blender/gen_fuser_3b",
                        device="cpu",
                        local_files_only=True  # é¿å…ç¬¦å·é“¾æ¥è­¦å‘Š
                    )
                    fuser_time = time.time() - start_time
                    self.fuser_loaded = True
                    logger.info(f"âœ… GenFuser åŠ è½½æˆåŠŸ ({fuser_time:.2f}s)")
                    logger.info("ğŸ“ GenFuser å·²é…ç½®æ”¯æŒæ›´é•¿è¾“å…¥ (è¿è¡Œæ—¶å°†ä½¿ç”¨ max_length=2048, candidate_max_length=512)")
                except Exception as e:
                    logger.warning(f"âš ï¸ GenFuser åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨ä»…æ’åºæ¨¡å¼: {str(e)}")
                    self.fuser_loaded = False
            else:
                logger.debug("â™»ï¸ GenFuser å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
            
            self.is_initialized = True
            logger.info("ğŸ‰ LLM-Blender æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼")
            logger.info(f"ğŸ“Š æœåŠ¡çŠ¶æ€: Ranker={'å·²åŠ è½½' if self.ranker_loaded else 'æœªåŠ è½½'}, Fuser={'å·²åŠ è½½' if self.fuser_loaded else 'æœªåŠ è½½'}")
            
        except Exception as e:
            logger.error(f"âŒ LLM-Blender åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.is_initialized = False
            raise e
    
    def contains_chinese(self, text: str) -> bool:
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        return any('\u4e00' <= char <= '\u9fff' for char in text)
    
    async def call_deepseek_api(
        self, 
        query: str, 
        top_responses: List[Dict[str, Any]], 
        instruction: Optional[str] = None
    ) -> str:
        """
        è°ƒç”¨ DeepSeek API è¿›è¡Œä¸­æ–‡å›ç­”èåˆ
        
        Args:
            query: ç”¨æˆ·åŸå§‹é—®é¢˜
            top_responses: æ’åºåçš„å‰å‡ ä¸ªå›ç­”
            instruction: å¯é€‰æŒ‡ä»¤
            
        Returns:
            DeepSeek èåˆåçš„å›ç­”
        """
        try:
            # æ„å»ºèåˆæç¤ºè¯
            fusion_prompt = self._build_fusion_prompt(query, top_responses, instruction)
            
            # å‡†å¤‡APIè¯·æ±‚
            headers = {
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå›ç­”èåˆä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å¤šä¸ªAIæ¨¡å‹çš„å›ç­”è¿›è¡Œæ™ºèƒ½èåˆï¼Œç”Ÿæˆä¸€ä¸ªæ›´å‡†ç¡®ã€æ›´å…¨é¢ã€æ›´æœ‰ç”¨çš„ç»¼åˆç­”æ¡ˆã€‚è¯·ä¿æŒå®¢è§‚ã€å‡†ç¡®ï¼Œå¹¶å°½å¯èƒ½ç»“åˆå„ä¸ªå›ç­”çš„ä¼˜ç‚¹ã€‚"
                    },
                    {
                        "role": "user", 
                        "content": fusion_prompt
                    }
                ],
                "temperature": 0.3,  # è¾ƒä½çš„æ¸©åº¦ç¡®ä¿ç¨³å®šè¾“å‡º
                "max_tokens": 2000,
                "stream": False
            }
            
            logger.info("ğŸ¤– è°ƒç”¨ DeepSeek API è¿›è¡Œä¸­æ–‡èåˆ...")
            start_time = time.time()
            
            # å‘é€å¼‚æ­¥è¯·æ±‚
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    DEEPSEEK_API_URL, 
                    headers=headers, 
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        fused_content = result["choices"][0]["message"]["content"]
                        
                        api_time = time.time() - start_time
                        logger.info(f"âœ… DeepSeek API èåˆå®Œæˆ ({api_time:.2f}s)")
                        logger.info(f"ğŸ“ èåˆç»“æœé•¿åº¦: {len(fused_content)} å­—ç¬¦")
                        
                        return fused_content
                    else:
                        error_text = await response.text()
                        logger.error(f"âŒ DeepSeek API é”™è¯¯ {response.status}: {error_text}")
                        raise Exception(f"DeepSeek API è°ƒç”¨å¤±è´¥: {response.status}")
                        
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥: {str(e)}")
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œé™çº§åˆ°ç®€å•èåˆ
            logger.info("â¬‡ï¸ é™çº§åˆ°ç®€å•æ–‡æœ¬èåˆ")
            return await self._simple_fusion_from_responses(query, top_responses)
    
    def _build_fusion_prompt(
        self, 
        query: str, 
        top_responses: List[Dict[str, Any]], 
        instruction: Optional[str] = None
    ) -> str:
        """æ„å»ºå‘é€ç»™ DeepSeek çš„èåˆæç¤ºè¯"""
        
        prompt_parts = []
        
        # æ·»åŠ æŒ‡ä»¤ï¼ˆå¦‚æœæœ‰ï¼‰
        if instruction:
            prompt_parts.append(f"**ä»»åŠ¡æŒ‡ä»¤**: {instruction}\n")
        
        # æ·»åŠ ç”¨æˆ·é—®é¢˜
        prompt_parts.append(f"**ç”¨æˆ·é—®é¢˜**: {query}\n")
        
        # æ·»åŠ å„ä¸ªAIæ¨¡å‹çš„å›ç­”
        prompt_parts.append("**å¤šä¸ªAIæ¨¡å‹çš„å›ç­”**:")
        
        for i, resp in enumerate(top_responses, 1):
            model_id = resp.get('modelId', f'æ¨¡å‹{i}')
            content = resp.get('content', '')
            quality_score = resp.get('quality_score', 0)
            
            prompt_parts.append(f"\n**å›ç­” {i} (æ¥æº: {model_id}, è´¨é‡åˆ†æ•°: {quality_score})**:")
            prompt_parts.append(content)
        
        # æ·»åŠ èåˆè¦æ±‚
        prompt_parts.append("""

**èåˆè¦æ±‚**:
1. è¯·ä»”ç»†åˆ†æä¸Šè¿°å„ä¸ªAIæ¨¡å‹çš„å›ç­”
2. è¯†åˆ«æ¯ä¸ªå›ç­”çš„ä¼˜ç‚¹å’Œä¸è¶³
3. å°†è¿™äº›å›ç­”çš„ä¼˜åŠ¿éƒ¨åˆ†è¿›è¡Œæ™ºèƒ½èåˆ
4. ç”Ÿæˆä¸€ä¸ªæ›´å‡†ç¡®ã€æ›´å…¨é¢ã€æ›´æœ‰æ¡ç†çš„ç»¼åˆç­”æ¡ˆ
5. ç¡®ä¿ç­”æ¡ˆé€»è¾‘æ¸…æ™°ï¼Œä¿¡æ¯å®Œæ•´
6. ä¿æŒä¸­æ–‡è¡¨è¾¾çš„è‡ªç„¶å’Œæµç•…
7. å¦‚æœå‘ç°å›ç­”ä¹‹é—´æœ‰å†²çªï¼Œè¯·ç»™å‡ºå¹³è¡¡çš„è§‚ç‚¹æˆ–è¯´æ˜ä¸åŒè§’åº¦

**è¯·ç›´æ¥ç»™å‡ºèåˆåçš„æœ€ç»ˆç­”æ¡ˆï¼Œä¸éœ€è¦é¢å¤–çš„è¯´æ˜æˆ–åˆ†æè¿‡ç¨‹**:""")
        
        return "\n".join(prompt_parts)
    
    async def rank_responses(
        self, 
        query: str, 
        responses: List[Dict[str, Any]], 
        instruction: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        å¯¹å¤šä¸ªAIå›ç­”è¿›è¡Œè´¨é‡æ’åº
        
        Args:
            query: ç”¨æˆ·çš„åŸå§‹é—®é¢˜
            responses: AIæ¨¡å‹çš„å›ç­”åˆ—è¡¨ [{"modelId": "xxx", "content": "xxx"}, ...]
            instruction: å¯é€‰çš„æŒ‡ä»¤å‰ç¼€
            
        Returns:
            æŒ‰è´¨é‡æ’åºåçš„å›ç­”åˆ—è¡¨ï¼Œæœ€ä¼˜å›ç­”åœ¨å‰
        """
        # æ‡’åŠ è½½æœºåˆ¶ï¼šå¦‚æœRankeræœªåŠ è½½ï¼Œå°è¯•é‡æ–°åŠ è½½
        if not await self._lazy_load_ranker():
            logger.error("âŒ æ— æ³•åŠ è½½Rankerï¼Œè¿”å›åŸå§‹å›ç­”é¡ºåº")
            return responses
        
        if len(responses) <= 1:
            return responses
            
        try:
            logger.debug(f"ğŸ” å¼€å§‹å¯¹ {len(responses)} ä¸ªå›ç­”è¿›è¡Œè´¨é‡æ’åº...")
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            inputs = [query]
            candidates = [[resp["content"] for resp in responses]]
            instructions = [instruction] if instruction else None
            
            # æ‰§è¡Œæ’åº
            start_time = time.time()
            ranks = self.blender.rank(
                inputs=inputs,
                candidates=candidates,
                instructions=instructions,
                return_scores=False,
                batch_size=1
            )[0]  # å–ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªï¼‰é—®é¢˜çš„æ’åºç»“æœ
            
            rank_time = time.time() - start_time
            logger.debug(f"âœ… æ’åºå®Œæˆ ({rank_time:.2f}s)")
            
            # æ ¹æ®æ’åºç»“æœé‡æ–°æ’åˆ—å›ç­”
            # å°†numpyæ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿ä½¿ç”¨indexæ–¹æ³•
            ranks_list = ranks.tolist() if hasattr(ranks, 'tolist') else list(ranks)
            ranked_responses = []
            for rank in range(1, len(responses) + 1):
                idx = ranks_list.index(rank)  # æ‰¾åˆ°æ’åä¸ºrankçš„å›ç­”ç´¢å¼•
                response = responses[idx].copy()
                response["rank"] = rank
                response["quality_score"] = len(responses) - rank + 1  # è´¨é‡åˆ†æ•°ï¼Œè¶Šé«˜è¶Šå¥½
                ranked_responses.append(response)
            
            # ç®€åŒ–æ—¥å¿—è¾“å‡º
            model_ranks = [f"{resp['modelId']}(æ’å{resp['rank']})" for resp in ranked_responses]
            logger.info(f"ğŸ“Š æ’åºç»“æœ: {model_ranks}")
            return ranked_responses
            
        except Exception as e:
            logger.error(f"âŒ æ’åºå¤±è´¥: {str(e)}")
            # æ’åºå¤±è´¥æ—¶è¿”å›åŸå§‹åˆ—è¡¨ï¼Œæ·»åŠ é»˜è®¤æ’å
            for i, resp in enumerate(responses):
                resp["rank"] = i + 1
                resp["quality_score"] = len(responses) - i
            return responses
    
    async def fuse_responses(
        self,
        query: str,
        responses: List[Dict[str, Any]],
        instruction: Optional[str] = None,
        top_k: int = 3
    ) -> str:
        """
        èåˆå¤šä¸ªAIå›ç­”ç”Ÿæˆæœ€ä¼˜ç­”æ¡ˆ
        
        æ™ºèƒ½ç­–ç•¥:
        - è‹±æ–‡è¾“å…¥: ä½¿ç”¨ GenFuser è¿›è¡Œé«˜è´¨é‡èåˆ
        - ä¸­æ–‡è¾“å…¥: ä½¿ç”¨ DeepSeek API è¿›è¡Œä¸“ä¸šä¸­æ–‡èåˆ
        
        Args:
            query: ç”¨æˆ·çš„åŸå§‹é—®é¢˜
            responses: AIæ¨¡å‹çš„å›ç­”åˆ—è¡¨ï¼ˆåº”è¯¥å·²ç»æ’åºï¼‰
            instruction: å¯é€‰çš„æŒ‡ä»¤å‰ç¼€
            top_k: ä½¿ç”¨å‰kä¸ªæœ€ä¼˜å›ç­”è¿›è¡Œèåˆ
            
        Returns:
            èåˆç”Ÿæˆçš„æœ€ä¼˜ç­”æ¡ˆ
        """
        if len(responses) <= 1:
            return responses[0]["content"] if responses else "æŠ±æ­‰ï¼Œæ²¡æœ‰å¯ç”¨çš„å›ç­”ã€‚"
        
        # é€‰æ‹©å‰top_kä¸ªå›ç­”
        top_responses = responses[:top_k]
        
        # æ£€æµ‹è¯­è¨€å¹¶é€‰æ‹©èåˆç­–ç•¥
        has_chinese = (self.contains_chinese(query) or 
                      any(self.contains_chinese(resp.get("content", "")) for resp in top_responses))
        
        if has_chinese:
            logger.info("ğŸˆ³ æ£€æµ‹åˆ°ä¸­æ–‡è¾“å…¥ï¼Œä½¿ç”¨ DeepSeek API è¿›è¡Œä¸“ä¸šä¸­æ–‡èåˆ")
            return await self.call_deepseek_api(query, top_responses, instruction)
        else:
            logger.info("ğŸ”¤ æ£€æµ‹åˆ°è‹±æ–‡è¾“å…¥ï¼Œä½¿ç”¨ GenFuser è¿›è¡Œé«˜è´¨é‡èåˆ")
            return await self._genfuser_fusion(query, top_responses, instruction, top_k)
    
    async def _genfuser_fusion(
        self,
        query: str,
        top_responses: List[Dict[str, Any]],
        instruction: Optional[str] = None,
        top_k: int = 3
    ) -> str:
        """ä½¿ç”¨ GenFuser è¿›è¡Œè‹±æ–‡èåˆï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        
        # æ‡’åŠ è½½æœºåˆ¶ï¼šå¦‚æœGenFuseræœªåŠ è½½ï¼Œå°è¯•é‡æ–°åŠ è½½
        if not await self._lazy_load_fuser():
            logger.warning("âš ï¸ GenFuseråŠ è½½å¤±è´¥ï¼Œé™çº§åˆ°ç®€å•èåˆ")
            return await self._simple_fusion_from_responses(query, top_responses)
            
        try:
            logger.info(f"âš¡ å¼€å§‹ GenFuser èåˆå‰ {len(top_responses)} ä¸ªæœ€ä¼˜å›ç­”...")
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            inputs = [query]
            instructions = [instruction] if instruction else None
            candidates = [[resp["content"] for resp in top_responses]]
            
            # ä¸´æ—¶ä¿®æ”¹fuseré…ç½®ä»¥æ”¯æŒæ›´é•¿çš„è¾“å…¥åºåˆ—
            original_max_length = self.blender.fuser_config.max_length
            original_candidate_maxlength = self.blender.fuser_config.candidate_maxlength
            
            # è®¾ç½®æ›´å¤§çš„è¾“å…¥å¤„ç†é•¿åº¦é™åˆ¶
            self.blender.fuser_config.max_length = 2048  # è¾“å…¥åºåˆ—çš„æœ€å¤§é•¿åº¦
            self.blender.fuser_config.candidate_maxlength = 1024  # å•ä¸ªå€™é€‰å›ç­”çš„æœ€å¤§é•¿åº¦
            
            logger.info(f"ğŸ“ ä¸´æ—¶è°ƒæ•´GenFuseré…ç½®: max_length={self.blender.fuser_config.max_length}, candidate_maxlength={self.blender.fuser_config.candidate_maxlength}")
            
            # æ‰§è¡Œèåˆç”Ÿæˆ
            start_time = time.time()
            fused_results = self.blender.fuse(
                inputs=inputs,
                candidates=candidates,
                instructions=instructions,
                batch_size=1,
                candidate_max_length=1024
            )
            
            # æ¢å¤åŸå§‹é…ç½®
            self.blender.fuser_config.max_length = original_max_length
            self.blender.fuser_config.candidate_maxlength = original_candidate_maxlength
            
            fuse_time = time.time() - start_time
            fused_content = fused_results[0] if fused_results else "èåˆç”Ÿæˆå¤±è´¥"
            
            logger.info(f"âœ… GenFuser èåˆå®Œæˆ ({fuse_time:.2f}s)")
            logger.info(f"ğŸ“ èåˆç»“æœé•¿åº¦: {len(fused_content)} å­—ç¬¦")
            
            # æ£€æŸ¥ç”Ÿæˆå†…å®¹è´¨é‡
            if "?" in fused_content and fused_content.count("?") > len(fused_content) * 0.3:
                logger.warning("âš ï¸ æ£€æµ‹åˆ°å¤§é‡é—®å·ï¼Œå¯èƒ½æ˜¯è§£ç é—®é¢˜ï¼Œé™çº§åˆ°ç®€å•èåˆ")
                return await self._simple_fusion_from_responses(query, top_responses)
            
            return fused_content
            
        except Exception as e:
            logger.error(f"âŒ GenFuser èåˆå¤±è´¥: {str(e)}")
            return await self._simple_fusion_from_responses(query, top_responses)
    
    async def rank_and_fuse(
        self,
        query: str,
        responses: List[Dict[str, Any]],
        instruction: Optional[str] = None,
        top_k: int = 3
    ) -> Dict[str, Any]:
        """
        ä¸€ä½“åŒ–æ’åºå’Œèåˆï¼šå…ˆæ’åºå†èåˆ
        
        æ™ºèƒ½ç­–ç•¥:
        - è‹±æ–‡: PairRMæ’åº + GenFuserèåˆ
        - ä¸­æ–‡: PairRMæ’åº + DeepSeek APIèåˆ
        
        Args:
            query: ç”¨æˆ·çš„åŸå§‹é—®é¢˜
            responses: AIæ¨¡å‹çš„å›ç­”åˆ—è¡¨
            instruction: å¯é€‰çš„æŒ‡ä»¤å‰ç¼€
            top_k: ç”¨äºèåˆçš„top-kå›ç­”æ•°é‡
            
        Returns:
            åŒ…å«æ’åºç»“æœå’Œèåˆç»“æœçš„å­—å…¸
        """
        # ç§»é™¤é‡å¤çš„åˆå§‹åŒ–æ£€æŸ¥ï¼Œç”±get_blender_serviceç»Ÿä¸€ç®¡ç†
        logger.debug(f"ğŸ”„ å¼€å§‹æ™ºèƒ½æ’åº+èåˆå¤„ç†...")
        start_time = time.time()
        
        # æ£€æµ‹è¯­è¨€
        has_chinese = (self.contains_chinese(query) or 
                      any(self.contains_chinese(resp.get("content", "")) for resp in responses))
        
        fusion_method = "deepseek_chinese" if has_chinese else "genfuser_english"
        logger.info(f"ğŸŒ è¯­è¨€æ£€æµ‹: {'ä¸­æ–‡' if has_chinese else 'è‹±æ–‡'}, èåˆç­–ç•¥: {fusion_method}")
        
        try:
            # 1. æ’åºï¼ˆPairRMå¯¹ä¸­è‹±æ–‡éƒ½æ”¯æŒè‰¯å¥½ï¼‰
            ranked_responses = await self.rank_responses(query, responses, instruction)
            
            # 2. èåˆï¼ˆæ ¹æ®è¯­è¨€é€‰æ‹©ç­–ç•¥ï¼‰
            fused_content = await self.fuse_responses(query, ranked_responses, instruction, top_k)
            
            total_time = time.time() - start_time
            
            result = {
                "fused_content": fused_content,
                "ranked_responses": ranked_responses,
                "best_response": ranked_responses[0] if ranked_responses else None,
                "processing_time": total_time,
                "models_used": [resp["modelId"] for resp in ranked_responses[:top_k]],
                "fusion_method": fusion_method,
                "language_detected": "chinese" if has_chinese else "english"
            }
            
            logger.info(f"ğŸ¯ æ™ºèƒ½å¤„ç†å®Œæˆ ({total_time:.2f}s)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½å¤„ç†å¤±è´¥: {str(e)}")
            raise e
    
    async def _simple_fusion_from_responses(self, query: str, responses: List[Dict[str, Any]]) -> str:
        """ä»å“åº”å¯¹è±¡åˆ—è¡¨è¿›è¡Œç®€å•èåˆçš„è¾…åŠ©æ–¹æ³•"""
        # è½¬æ¢ä¸ºåŸæœ‰æ ¼å¼
        simple_responses = []
        for resp in responses:
            simple_resp = {
                "modelId": resp.get("modelId", "unknown"),
                "content": resp.get("content", "")
            }
            simple_responses.append(simple_resp)
        
        return await self._simple_fusion(query, simple_responses, len(responses))
    
    async def _simple_fusion(self, query: str, responses: List[Dict[str, Any]], top_k: int) -> str:
        """ç®€å•çš„æ–‡æœ¬èåˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
        logger.info("ğŸ“ ä½¿ç”¨ç®€å•æ–‡æœ¬èåˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ...")
        
        if not responses:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰å¯ç”¨çš„å›ç­”ã€‚"
        
        if len(responses) == 1:
            return responses[0]["content"]
        
        # é€‰æ‹©top-kå›ç­”
        top_responses = responses[:top_k]
        
        # æ„å»ºèåˆå›ç­”
        fusion_parts = []
        fusion_parts.append(f"åŸºäº {len(top_responses)} ä¸ªAIæ¨¡å‹çš„å›ç­”ï¼Œä¸ºæ‚¨æä¾›ä»¥ä¸‹ç»¼åˆç­”æ¡ˆï¼š\n")
        
        # å¦‚æœæœ‰æ˜æ˜¾çš„æœ€ä½³å›ç­”ï¼Œä»¥å®ƒä¸ºä¸»
        best_response = top_responses[0]
        fusion_parts.append(f"**ä¸»è¦è§‚ç‚¹** (æ¥æº: {best_response['modelId']}):\n{best_response['content']}\n")
        
        # å¦‚æœæœ‰å…¶ä»–é«˜è´¨é‡å›ç­”ï¼Œæ·»åŠ è¡¥å……è§‚ç‚¹
        if len(top_responses) > 1:
            fusion_parts.append("**è¡¥å……è§‚ç‚¹**:")
            for resp in top_responses[1:]:
                fusion_parts.append(f"- {resp['modelId']}: {resp['content'][:200]}{'...' if len(resp['content']) > 200 else ''}")
        
        return "\n".join(fusion_parts)

    async def _lazy_load_ranker(self) -> bool:
        """æ‡’åŠ è½½Rankeræ¨¡å‹"""
        if self.ranker_loaded:
            return True
            
        try:
            logger.info("ğŸ”„ æ‡’åŠ è½½ PairRM Ranker...")
            if self.blender is None:
                self.blender = llm_blender.Blender()
            
            start_time = time.time()
            self.blender.loadranker(
                "llm-blender/PairRM",
                device="cpu"
            )
            ranker_time = time.time() - start_time
            self.ranker_loaded = True
            logger.info(f"âœ… Ranker æ‡’åŠ è½½æˆåŠŸ ({ranker_time:.2f}s)")
            return True
        except Exception as e:
            logger.error(f"âŒ Rankeræ‡’åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    async def _lazy_load_fuser(self) -> bool:
        """æ‡’åŠ è½½GenFuseræ¨¡å‹"""
        if self.fuser_loaded:
            return True
            
        try:
            logger.info("ğŸ”„ æ‡’åŠ è½½ GenFuser...")
            if self.blender is None:
                self.blender = llm_blender.Blender()
            
            start_time = time.time()
            self.blender.loadfuser(
                "llm-blender/gen_fuser_3b",
                device="cpu",
                local_files_only=True
            )
            fuser_time = time.time() - start_time
            self.fuser_loaded = True
            logger.info(f"âœ… GenFuser æ‡’åŠ è½½æˆåŠŸ ({fuser_time:.2f}s)")
            logger.info("ğŸ“ GenFuser é…ç½®: æ”¯æŒæ›´é•¿è¾“å…¥ (max_length=2048, candidate_max_length=512)")
            return True
        except Exception as e:
            logger.error(f"âŒ GenFuseræ‡’åŠ è½½å¤±è´¥: {str(e)}")
            return False

# å…¨å±€æœåŠ¡å®ä¾‹
_blender_service = None
_service_lock = asyncio.Lock()  # æ·»åŠ é”ç¡®ä¿çº¿ç¨‹å®‰å…¨

async def get_blender_service() -> LLMBlenderService:
    """è·å–å…¨å±€LLM-BlenderæœåŠ¡å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼ï¼‰"""
    global _blender_service
    
    # ä½¿ç”¨é”ç¡®ä¿åªæœ‰ä¸€ä¸ªå®ä¾‹è¢«åˆ›å»º
    async with _service_lock:
        if _blender_service is None:
            logger.info("ğŸ—ï¸ åˆ›å»ºæ–°çš„ LLM-Blender æœåŠ¡å®ä¾‹...")
            _blender_service = LLMBlenderService()
            await _blender_service.initialize()
            logger.info("âœ… å…¨å±€ LLM-Blender æœåŠ¡å®ä¾‹åˆ›å»ºå®Œæˆ")
        else:
            logger.debug("â™»ï¸ é‡ç”¨ç°æœ‰çš„ LLM-Blender æœåŠ¡å®ä¾‹")
    
    return _blender_service

# å¯¹å¤–æ¥å£å‡½æ•°
async def get_advanced_fusion_response(
    query: str,
    responses: List[Dict[str, Any]], 
    instruction: Optional[str] = None,
    top_k: int = 3,
    fusion_method: str = "rank_and_fuse"
) -> Dict[str, Any]:
    """
    é«˜çº§èåˆæœåŠ¡ä¸»å…¥å£
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        responses: AIå›ç­”åˆ—è¡¨ [{"modelId": "xxx", "content": "xxx"}, ...]
        instruction: å¯é€‰æŒ‡ä»¤
        top_k: èåˆä½¿ç”¨çš„å›ç­”æ•°é‡
        fusion_method: èåˆæ–¹æ³• ("rank_only", "fuse_only", "rank_and_fuse")
        
    Returns:
        èåˆç»“æœå­—å…¸
    """
    try:
        service = await get_blender_service()
        logger.debug(f"ğŸ”§ ä½¿ç”¨èåˆæ–¹æ³•: {fusion_method}, top_k: {top_k}")
        
        if fusion_method == "rank_only":
            ranked = await service.rank_responses(query, responses, instruction)
            return {
                "fused_content": ranked[0]["content"] if ranked else "",
                "ranked_responses": ranked,
                "fusion_method": "rank_only"
            }
        elif fusion_method == "fuse_only":
            fused = await service.fuse_responses(query, responses, instruction, top_k)
            return {
                "fused_content": fused,
                "ranked_responses": responses,
                "fusion_method": "fuse_only"
            }
        else:  # rank_and_fuse
            return await service.rank_and_fuse(query, responses, instruction, top_k)
            
    except Exception as e:
        logger.error(f"âŒ é«˜çº§èåˆæœåŠ¡å¤±è´¥: {str(e)}")
        # é™çº§åˆ°ç®€å•èåˆ
        if responses:
            return {
                "fused_content": responses[0]["content"],
                "ranked_responses": responses,
                "fusion_method": "fallback",
                "error": str(e)
            }
        else:
            return {
                "fused_content": "æŠ±æ­‰ï¼ŒèåˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚",
                "ranked_responses": [],
                "fusion_method": "error",
                "error": str(e)
            } 